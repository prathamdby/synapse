---
globs: database.py,*db*.py,*database*.py
---

# Database Management Patterns

## Core Database Architecture

This rule applies to database management code, specifically patterns used in [database.py](mdc:database.py) for SQLite operations with async support.

## Database Connection Patterns

### 1. Context Manager Usage

Always use async context managers for database connections:

```python
# Good: Async context manager ensures proper connection cleanup
async def get_or_create_user(self, user_id: int) -> Dict[str, Any]:
    async with aiosqlite.connect(self.db_path) as db:
        cursor = await db.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        user = await cursor.fetchone()

        if user:
            # Update last active timestamp
            await db.execute(
                "UPDATE users SET last_active = CURRENT_TIMESTAMP WHERE user_id = ?",
                (user_id,)
            )
            await db.commit()
        # Connection automatically closed when exiting context
```

### 2. Transaction Management

Group related operations in transactions:

```python
# Good: Multiple operations in single transaction
async def update_conversation_history(self, user_id: int, messages: List[Dict[str, Any]]):
    async with aiosqlite.connect(self.db_path) as db:
        history_json = json.dumps(messages)

        # Check if conversation exists
        cursor = await db.execute("SELECT id FROM conversations WHERE user_id = ?", (user_id,))
        existing = await cursor.fetchone()

        if existing:
            await db.execute(
                """UPDATE conversations
                   SET conversation_history = ?, last_updated = CURRENT_TIMESTAMP,
                       message_count = ?
                   WHERE user_id = ?""",
                (history_json, len(messages), user_id)
            )
        else:
            await db.execute(
                """INSERT INTO conversations (user_id, conversation_history, message_count)
                   VALUES (?, ?, ?)""",
                (user_id, history_json, len(messages))
            )

        await db.commit()  # Single commit for all operations
```

## Schema Design Patterns

### 1. Table Creation with Constraints

Design tables with proper constraints and defaults:

```python
# Good: Comprehensive table definition with constraints
await db.execute("""
    CREATE TABLE IF NOT EXISTS users (
        user_id INTEGER PRIMARY KEY,
        username TEXT,
        first_name TEXT,
        last_name TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        is_active BOOLEAN DEFAULT 1,
        preferred_model TEXT DEFAULT 'gpt-oss-120b'
    )
""")

# Good: Foreign key relationships
await db.execute("""
    CREATE TABLE IF NOT EXISTS conversations (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER,
        conversation_history TEXT,
        last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        message_count INTEGER DEFAULT 0,
        FOREIGN KEY (user_id) REFERENCES users (user_id)
    )
""")
```

### 2. Database Migration Patterns

Handle schema changes with migration logic:

```python
# Good: Safe database migration with error handling
async def _migrate_database(self, db):
    """Handle database migrations."""
    try:
        # Check current schema
        cursor = await db.execute("PRAGMA table_info(users)")
        columns = await cursor.fetchall()
        column_names = [column[1] for column in columns]

        # Add missing columns
        if "preferred_model" not in column_names:
            logger.info("Adding preferred_model column to users table")
            await db.execute(
                "ALTER TABLE users ADD COLUMN preferred_model TEXT DEFAULT 'gpt-oss-120b'"
            )
            await db.commit()
            logger.info("Database migration completed successfully")
    except Exception as e:
        logger.error(f"Database migration error: {e}")
        # Continue with initialization even if migration fails
```

### 3. Index Strategy

Create indexes for frequently queried columns:

```python
# Good: Create indexes for performance
await db.execute("CREATE INDEX IF NOT EXISTS idx_users_user_id ON users(user_id)")
await db.execute("CREATE INDEX IF NOT EXISTS idx_conversations_user_id ON conversations(user_id)")
await db.execute("CREATE INDEX IF NOT EXISTS idx_rate_limits_user_id ON rate_limits(user_id)")
```

## Data Access Patterns

### 1. Parameterized Queries

Always use parameterized queries to prevent SQL injection:

```python
# Good: Parameterized queries
cursor = await db.execute(
    "SELECT * FROM users WHERE user_id = ?",
    (user_id,)
)

# Good: Multiple parameters
await db.execute(
    """INSERT INTO users (user_id, username, first_name, last_name)
       VALUES (?, ?, ?, ?)""",
    (user_id, username, first_name, last_name)
)

# Never do this (SQL injection risk):
# await db.execute(f"SELECT * FROM users WHERE user_id = {user_id}")
```

### 2. Result Processing

Handle query results consistently:

```python
# Good: Convert cursor results to dictionaries
async def get_user_stats(self, user_id: int) -> Dict[str, Any]:
    async with aiosqlite.connect(self.db_path) as db:
        cursor = await db.execute("""
            SELECT
                u.username, u.first_name, u.created_at, u.last_active,
                COALESCE(c.message_count, 0) as total_messages,
                COUNT(mr.id) as reaction_count
            FROM users u
            LEFT JOIN conversations c ON u.user_id = c.user_id
            LEFT JOIN message_reactions mr ON u.user_id = mr.user_id
            WHERE u.user_id = ?
            GROUP BY u.user_id
        """, (user_id,))

        result = await cursor.fetchone()
        if result:
            # Convert to dictionary using column names
            columns = [desc[0] for desc in cursor.description]
            return dict(zip(columns, result))
        return {}
```

### 3. JSON Data Handling

Handle JSON serialization/deserialization safely:

```python
# Good: Safe JSON handling with error recovery
async def get_conversation_history(self, user_id: int) -> List[Dict[str, Any]]:
    async with aiosqlite.connect(self.db_path) as db:
        cursor = await db.execute(
            "SELECT conversation_history FROM conversations WHERE user_id = ? ORDER BY last_updated DESC LIMIT 1",
            (user_id,)
        )
        result = await cursor.fetchone()

        if result and result[0]:
            try:
                return json.loads(result[0])
            except json.JSONDecodeError:
                logger.error(f"Failed to decode conversation history for user {user_id}")
                return []  # Return empty list instead of crashing
        return []
```

## Performance Optimization Patterns

### 1. Efficient Queries

Write efficient queries with proper joins:

```python
# Good: Single query with joins instead of multiple queries
async def get_user_stats(self, user_id: int) -> Dict[str, Any]:
    async with aiosqlite.connect(self.db_path) as db:
        cursor = await db.execute("""
            SELECT
                u.username, u.first_name, u.created_at, u.last_active,
                COALESCE(c.message_count, 0) as total_messages,
                COUNT(mr.id) as reaction_count
            FROM users u
            LEFT JOIN conversations c ON u.user_id = c.user_id
            LEFT JOIN message_reactions mr ON u.user_id = mr.user_id
            WHERE u.user_id = ?
            GROUP BY u.user_id
        """, (user_id,))
```

### 2. Batch Operations

Use batch operations for multiple records:

```python
# Good: Batch insert for multiple records
async def batch_insert_reactions(self, reactions: List[Tuple[int, int, str]]):
    async with aiosqlite.connect(self.db_path) as db:
        await db.executemany(
            """INSERT INTO message_reactions (user_id, message_id, reaction_emoji)
               VALUES (?, ?, ?)""",
            reactions
        )
        await db.commit()
```

### 3. Connection Pooling Considerations

For high-load applications, consider connection pooling:

```python
# Good: Connection pool configuration for high load
class DatabaseManager:
    def __init__(self, db_path: str = "./bot_database.db", max_connections: int = 10):
        self.db_path = db_path
        self.max_connections = max_connections
        # Note: aiosqlite doesn't have built-in pooling,
        # but you can implement it or use aiopg/asyncpg for PostgreSQL
```

## Error Handling and Resilience

### 1. Database Error Recovery

Handle common database errors gracefully:

```python
# Good: Specific error handling
async def check_rate_limit(self, user_id: int, max_messages: int, window_seconds: int) -> bool:
    try:
        async with aiosqlite.connect(self.db_path) as db:
            # Rate limiting logic
            pass
    except aiosqlite.DatabaseError as e:
        logger.error(f"Database error in rate limiting: {e}")
        # Fail open - allow the request to proceed
        return True
    except Exception as e:
        logger.error(f"Unexpected error in rate limiting: {e}")
        return True
```

### 2. Data Validation

Validate data before database operations:

```python
# Good: Input validation
async def set_user_preferred_model(self, user_id: int, model: str):
    if not isinstance(user_id, int) or user_id <= 0:
        raise ValueError("Invalid user_id")

    if not model or not isinstance(model, str):
        raise ValueError("Invalid model name")

    async with aiosqlite.connect(self.db_path) as db:
        await db.execute(
            "UPDATE users SET preferred_model = ? WHERE user_id = ?",
            (model, user_id)
        )
        await db.commit()
```

### 3. Database Integrity Checks

Implement integrity checks for critical operations:

```python
# Good: Verify operations completed successfully
async def update_conversation_history(self, user_id: int, messages: List[Dict[str, Any]]):
    async with aiosqlite.connect(self.db_path) as db:
        # Update operation
        cursor = await db.execute(
            """UPDATE conversations
               SET conversation_history = ?, message_count = ?
               WHERE user_id = ?""",
            (json.dumps(messages), len(messages), user_id)
        )

        # Verify the update affected a row
        if cursor.rowcount == 0:
            logger.warning(f"No conversation record found for user {user_id}, creating new one")
            await db.execute(
                """INSERT INTO conversations (user_id, conversation_history, message_count)
                   VALUES (?, ?, ?)""",
                (user_id, json.dumps(messages), len(messages))
            )

        await db.commit()
```

## Rate Limiting Implementation

### 1. Sliding Window Rate Limiting

Implement efficient rate limiting with sliding windows:

```python
# Good: Sliding window rate limiting
async def check_rate_limit(self, user_id: int, max_messages: int, window_seconds: int) -> bool:
    async with aiosqlite.connect(self.db_path) as db:
        cursor = await db.execute(
            "SELECT message_count, window_start FROM rate_limits WHERE user_id = ?",
            (user_id,)
        )
        result = await cursor.fetchone()

        current_time = datetime.now()

        if result:
            message_count, window_start = result
            window_start = datetime.fromisoformat(window_start)

            # Check if window has expired
            if (current_time - window_start).seconds >= window_seconds:
                # Reset window
                await db.execute(
                    """UPDATE rate_limits
                       SET message_count = 1, window_start = ?
                       WHERE user_id = ?""",
                    (current_time.isoformat(), user_id)
                )
                await db.commit()
                return True
            elif message_count < max_messages:
                # Increment counter
                await db.execute(
                    "UPDATE rate_limits SET message_count = message_count + 1 WHERE user_id = ?",
                    (user_id,)
                )
                await db.commit()
                return True
            else:
                return False  # Rate limit exceeded
        else:
            # First message from user
            await db.execute(
                "INSERT INTO rate_limits (user_id, message_count, window_start) VALUES (?, 1, ?)",
                (user_id, current_time.isoformat())
            )
            await db.commit()
            return True
```

## Data Cleanup and Maintenance

### 1. Conversation History Pruning

Implement data pruning to manage storage:

```python
# Good: Automatic data pruning
async def prune_old_conversations(self, days_to_keep: int = 30):
    """Remove old conversation data to manage storage."""
    cutoff_date = datetime.now() - timedelta(days=days_to_keep)

    async with aiosqlite.connect(self.db_path) as db:
        cursor = await db.execute(
            "DELETE FROM conversations WHERE last_updated < ?",
            (cutoff_date.isoformat(),)
        )

        deleted_count = cursor.rowcount
        await db.commit()

        logger.info(f"Pruned {deleted_count} old conversation records")
```

### 2. Database Vacuum Operations

Regular maintenance operations:

```python
# Good: Database maintenance
async def maintenance_vacuum(self):
    """Perform database maintenance operations."""
    async with aiosqlite.connect(self.db_path) as db:
        await db.execute("VACUUM")
        await db.execute("ANALYZE")
        logger.info("Database maintenance completed")
```
